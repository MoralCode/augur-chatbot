# docker-compose.yml
# This file defines the multi-container application setup.
# To run: docker-compose up --build

version: '3.8'

services:
  # Ollama Service: Runs the core Ollama model server.
  ollama:
    image: ollama/ollama
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - ~/.ollama:/root/.ollama:Z
    restart: unless-stopped
    networks:
      - ollama_net

  # LlamaStack Service: Provides the distribution layer.
  llamastack:
    image: llamastack/distribution-ollama:0.2.9
    container_name: llamastack
    ports:
      - "8321:8321"
    volumes:
      - ~/.llama:/root/.llama:Z
    environment:
      - INFERENCE_MODEL=llama3.2:3b-instruct-fp16
      # This hostname 'ollama' works because both services are on the same Docker network.
      - OLLAMA_URL=http://ollama:11434
    depends_on:
      - ollama
    restart: unless-stopped
    networks:
      - ollama_net

  # MCP Registration Service: Runs the registration script.
  register_mcp:
    build: .
    container_name: register_mcp
    command: python /app/register_mcp.py
    depends_on:
      - llamastack # Waits for llamastack to be healthy before starting.
    restart: on-failure
    networks:
      - ollama_net

  # MCP Execution Service: Runs the Uvicorn server for the main application.
  mcp_execute:
    build: .
    container_name: mcp_execute
    command: uvicorn mcp_execute:app --host 0.0.0.0 --port 9002 --app-dir /app
    ports:
      - "9002:9002"
    depends_on:
      - llamastack
    restart: unless-stopped
    networks:
      - ollama_net

  # Streamlit UI Service: Runs the user interface.
  streamlit_ui:
    build: .
    container_name: streamlit_ui
    command: streamlit run /app/ui.py --server.port=8501 --server.address=0.0.0.0
    ports:
      - "8501:8501" # Default streamlit port
    environment:
      # The UI needs to know where the LlamaStack service is.
      - BASE_URL=http://llamastack:8321
    depends_on:
      - llamastack
    restart: unless-stopped
    networks:
      - ollama_net

# Network to allow services to communicate with each other by name.
networks:
  ollama_net:
    driver: bridge